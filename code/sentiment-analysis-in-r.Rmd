---
title: "Sentiment Analysis in R"
author: "Jenn Schilling"
date: "9/16/2021"
output: html_document
---

# Introduction

This file contains the code for webinar: [Sentiment Analysis in R](https://www.airweb.org/collaborate-learn/calendar/2021/10/20/event/sentiment-analysis-in-r), presented for the Association for Institutional Research, October 20 & 22 2021.  

**Webinar Details**  
This webinar will teach participants how to complete a text analysis in R, including data processing and cleaning, visualization of word frequencies, and sentiment analysis. Sentiment analysis is useful for finding patterns in text data from open response questions on surveys and course evaluations as well as evaluating social media posts. This series is ideal for higher education professionals who have some experience in R and want to add text analysis to their R skills.

As a result of this webinar, participants will be able to: 
- Prepare data for a text analysis in R. 
- Conduct text mining in R.
- Complete sentiment analysis in R. 

**Materials developed by Jenn Schilling.**  

# Setup

Load libraries and tweet data.

```{r setup, message = FALSE}

library(here) # working directory
library(tidyverse) # data processing and plotting
library(tidytext) # text analysis

# Read data
text_data <- read_csv(here("data", "uarizona_tweets.csv"), show_col_types = FALSE)

```

# Data Processing

The first step is to understand and process the data. This particular dataset is a subset of what is pulled from the `rtweet` package. The full data includes more details about the tweet and engagement with it, but this subset includes the date, user, tweet text, source, and a few other metrics that may be of interest. 

Now maybe you do not want to look at tweets, the same process we are going to walk through in this webinar could be used for any type of text data. I pulled Twitter data to use publicly accessible data that is relevant to my institution, using hashtags that are related to my university, so that I would have a good demonstration dataset. But this same process would work with any text dataset, you would just adjust the code to read the data in the "Setup" chunk above.

One important part of text analysis is having an identification column. Since we will eventually be creating a data frame of individual words, we want to be able to tie those words back to the original text (in this case, tweet). Having an identification column allows us to tie back to the original text. In this case, we will use the `status_id` field to identify each tweet.

```{r view-data}

# First let's look at the data
View(text_data)

# Check the number of rows and columns
dim(text_data)

# View the data types of the columns
glimpse(text_data)

```

Once we have a basic understanding of the data, we need to process it. We will need to expand contractions, remove special characters and emojis, and make everything lowercase. We also want to make the `status_id` column a character column instead of a numeric column.

```{r process-data}

text_data_processed <- text_data %>%
  
# Expand contractions
  mutate() %>%
  
# Remove emojis
  mutate(text = gsub("\U0001", "", text)) %>%
  
# Remove links
  mutate(text = gsub("(https:|http:).*", "", text)) %>%
  
# Remove special characters
  mutate(text =  gsub("[^a-zA-Z0-9 ]", " ", text)) %>%
  
# Lowercase
  mutate(text = str_to_lower(text)) %>%
  
# Remove extra whitespace
  mutate(text = str_squish(text)) %>%
  
# Make identification column a character
  mutate(status_id = as.character(status_id))

```


# Tokenizing

# Word Frequencies

# Sentiment Analysis

# Visualizing Results

# Moving Beyond Words
